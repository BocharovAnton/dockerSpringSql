package com.example.dockerspringbootpostgres.Service;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import com.example.dockerspringbootpostgres.Entity.Group;
import com.example.dockerspringbootpostgres.Entity.Speciality;
import com.example.dockerspringbootpostgres.Entity.Student;
import lombok.Getter;
import lombok.Setter;


import java.util.*;

@Getter
@Setter
public class DataGenerator {
    Random rand = new Random();
    private Integer studentCode = 15000;
    private final List<String> names = new ArrayList<>(Arrays.asList(
            "Клара Викторовна Дейнина", "Георгий Юрьевич Жмалов", "Тамара Василевна Чайничкова", "Алена Викторовна Кантаева", "Клара Аркадьевна Фоминцова", "Артём Алексеевич Гамалеев", "Елизавета Аркадьевна Воргалова", "Борис Евгеньевич Струлев", "Алина Аркадьевна Шулутова", "Екатерина Алексеевна Киткова", "Иван Евгеньевич Буцыкин", "Руслан Борисович Типугин", "Катерина Леонидовна Ременькова", "Игорь Николаевич Коптелов", "Алла Романовна Жежурина", "Наталья Яковлевна Мезенцова", "Максим Валериевич Кисихин", "Эдуард Тимофеевич Стуцкий", "Ева Егоровна Радкеева", "Александра Никитична Юлаева", "Дмитрий Аркадиевич Путицкий", "Евгения Ивановна Ляпичева", "Роман Максимович Умаров", "Маргарита Валерьевна Иммореева", "Пётр Василиевич Шмитов", "Олег Фёдорович Кильдушкин", "Юрий Петрович Угольцов", "Михаил Юриевич Богдашин", "Ярослав Юрьевич Мелузов", "София Евгеньевна Заорская", "Артём Петрович Телентинов", "Павел Фёдорович Гаторинов", "Вероника Олеговна Саралаева", "Карина Николаевна Бронская", "Иван Леонидович Аранин", "Герасим Николаевич Бочакин", "Оксана Богдановна Петряшова", "Антон Павлович Аверичев", "Светлана Никитична Пентина", "Раиса Олеговна Гудайкина", "Евгения Федоровна Суходеева", "Алиса Яковлевна Правдюкова", "Георгий Антонович Столоногов", "Георгий Георгиевич Христнев", "Михаил Антонович Хаммов", "Марина Василевна Пчелина", "Семён Юрьевич Пыликов", "Алла Эдуардовна Брюнова", "Вероника Андреевна Шешелева", "Марина Романовна Лелекина", "Руслан Яковлевич Чиколин", "Виктор Кириллович Бродулев", "Инна Борисовна Посцелова", "Антон Валериевич Завельский", "Денис Кириллович Мазалецкий", "Кирилл Николаевич Дудовцев", "Антон Сергеевич Самохватов", "Оксана Викторовна Урбанская", "Любовь Алексеевна Мужицкая", "Алиса Петровна Вьюгова", "Виктория Андреевна Рахлеева", "Георгий Игоревич Скальский", "Светлана Аркадьевна Абалкина", "Зинаида Андреевна Жагурина", "Василий Олегович Дружбин", "Артур Кириллович Болтенков", "Аркадий Сергеевич Маканин", "Светлана Михайловна Борминская", "Валерия Валерьевна Скодтаева", "Григорий Сергеевич Тропанов", "Ольга Эдуардовна Габинова", "Максим Аркадиевич Патюков", "Вера Игоревна Кисурина", "Ирина Эдуардовна Любарская", "Семён Иванович Каноков", "Тарас Фёдорович Уварушкин", "Никита Максимович Головлин", "Оксана Егоровна Чепурнова", "Виктор Борисович Маначаров", "Илья Михаилович Юхнев", "Тамара Максимовна Димитрова", "Надежда Игоревна Куронова", "Инна Максимовна Суркина", "Елена Эдуардовна Широнова", "Федор Вадимович Гонзалев", "Павел Николаевич Леваев", "Лариса Василевна Таова", "Валентина Богдановна Бегенжова", "Владислав Романович Шандыков", "Станислав Романович Путилин", "Анастасия Богдановна Жибарова", "Михаил Максимович Тургамбаев", "Лариса Яковлевна Горисова", "Альберт Романович Зулкарниев", "Роман Василиевич Картушин", "Вероника Игоревна Плигунова", "Ольга Валерьевна Графуткина", "Яков Олегович Ловнев", "Кира Яковлевна Яфизова", "Михаил Алексиевич Чурков"
    ));
    private final List<String> consonant = new ArrayList<>(Arrays.asList("Р","Б","Н","С"));
    private final List<String> secondpos = new ArrayList<>(Arrays.asList("И","С"));
    private final List<String> thirdpos = new ArrayList<>(Arrays.asList("Б","С"));
    private String getRandomGroupCode(){
        return consonant.get(rand.nextInt(consonant.size()))
                + secondpos.get(rand.nextInt(secondpos.size()))
                + thirdpos.get(rand.nextInt(thirdpos.size()))
                + "О";
    }
    public int GetNextStudentCode(){return studentCode++;}
    public String getRandomName(){
        return names.get(rand.nextInt(names.size()));
    }
    public String getRandomLecture(){
        return lectures.get(rand.nextInt(lectures.size()));
    }

    public Group getGroup(Speciality speciality, Set<Student> studentsList){
        Group group = new Group();
        group.setGroupCode(getRandomGroupCode());
        group.setStudentsList(studentsList);
        group.setSpeciality(speciality);
        return group;
    }
    public Student getStudent(){
        Student newStudent = new Student();
        newStudent.setId(GetNextStudentCode());
        String tmpName = getRandomName();
        return newStudent;
    }
    ArrayList<String> lectures = new ArrayList<String>(){{
        add("Принципы построения, проектирования и эксплуатации ИС. Лекция 4.\n" +
            "Кратко рассмотрим возможности конфигурирования Storage Account в целом. Прежде всего, доступен File Explorer — бесплатная программа от Microsoft, позволяющая просматривать содержимое всех сервисов всех аккаунтов хранения.\n" +
            "На рисунке можно увидеть результат выборки программы из хранилища Table Storage (таблица events), которая содержит тестовые данные телеметрии, полученные путем приема сообщений через сервисы концентратора EventHub и потоковой аналитики Stream Analytics Job).\n" +
            " Внешний вид программы File Explorer от Microsoft\n" +
            "Чтобы обеспечить доступ к аккаунту извне, необходимо знать ключи доступа и URL, которые доступны на вкладке Access Keys\n" +
            "Ключи доступа и строки подключения к Storage Account\n" +
            " \n" +
            "Две пары ключей или строк подключения нужны для обеспечения «бесшовного» обновления ключей. Для этого первоначально используется ключ key1, затем клиенты переключаются на ключ key2, а ключ key1 обновляется. После этого клиенты переключаются на новый ключ key1, а ключ key2 обновляется.\n" +
            "Страница конфигурирования аккаунта в целом позволяет менять тип аккаунта (Account kind), уровень производительности (Performance).\n" +
            " Вкладка конфигурирования типа аккаунта, уровня производительности и репликации\n" +
            "Кподобным манипуляциям следует отнестись внимательно, поскольку каждый уровень имеет различную стоимость, а также переключение между ними может занять время, если в аккаунте много данных.\n" +
            "Следующий важный конфигурируемый параметр — Shared access signature (SAS)\n" +
            " \n" +
            "Вкладка конфигурирования типа аккаунта, уровня производительности и репликации\n" +
            "Концепция SAS состоит в том, что к объектам, расположенным в Storage Account, можно предоставить прямой доступ для скачивания — с помощью URL, который содержит ряд ограничивающих параметров, а именно: время жизни ссылки и ограничения IPадресов, с которых доступен ресурс. Эти параметры подписываются ключом аккаунта, и данная подпись добавляется в конец URL, по которому данный ресурс может быть доступен.\n" +
            "Теперь подробнее познакомимся с отдельными сервисами хранения файлов Storage Account.\n" +
            "Сервис Azure BLOB Storage предназначен для хранения различных файлов, потому и называется хранилищем больших двоичных объектов (Binary Large OBjects Storage, BLOB). Двоичные объекты могут храниться в нем как непосредственно, так и будучи размещенными в контейнерах (не путайте с Dockerконтейнерами, речь идет о контейнерах BLOB Storage) или на виртуальных дисках, тоже расположенных в BLOB Storage Account. Чтобы прояснить ситуацию, рассмотрим схему\n" +
            "Структура вложенности объектов в хранилище BLOB\n" +
            "Аккаунт Azure может содержать один или несколько Storage-аккаунтов. Каждый такой аккаунт способен непосредственно хранить файлы, виртуальные жесткие диски и контейнеры BLOB. Последние, в свою очередь, тоже могут включать файлы, виртуальные жесткие диски и другие контейнеры. Таким образом, c помощью контейнеров BLOB реализована иерархическая структура организации файлов.\n" +
            "На самом деле в BLOB Storage могут храниться любые файлы: текстовые, двоичные и др., но для разных типов хранимых объектов требуется разный тип BLOB. Всего есть три типа BLOB: Page BLOB, Block BLOB и Append BLOB.\n" +
            "Page BLOB — бинарный объект со страничной организацией памяти. Этот тип используется только для размещения виртуальных жестких дисков виртуальных машин.\n" +
            " \n" +
            "Block BLOB — BLOB с блочной организацией памяти, служащий для хранения всех видов файлов (кроме VHD), включая контейнеры BLOB. Это основной тип хранения файлов в BLOB Storage обычных файлов.\n" +
            "Append Block — BLOB с блочной организацией памяти, представляющий собой текстовый файл, размещенный в Azure Storage и допускающий добавление новой записи в конец файла. В остальных типах BLOB файлы нередактируемые, то есть, чтобы отредактировать файл, его необходимо скачать, открыть, отредактировать и закачать обратно. Понятно, что эти действия сопряжены с большими трудностями при работе с файлами логов. В то же время Append Block как раз оптимизирован для сценариев прямой записи логов.\n" +
            "Все объекты, расположенные в BLOB Storage, могут быть доступны через вебпотрал, с помощью SDK, команд расширения командной оболочки, а также по прямой ссылке.\n" +
            "Доступ к Storage-аккаунту с помощью веб-портала позволяет создавать файлы, контейнеры, просматривать список файлов, добавлять, удалять и загружать их, менять области видимости файлов (они могут быть общедоступными по ссылке, закрытыми для всех, кроме сервисов Azure). Интерфейс веб-портала удобен для работы с небольшим количеством файлов. Добавлять в облачное хранилище через веб-портал можно файлы не слишком большого размера. А вот файлы, загружаемые из облака, могут быть любого размера, допустимого в хранилище. Кроме того, для файлов можно открыть общий доступ, и они станут доступными для скачивания по ссылке. Доступ может быть открыт для файлов как в корневом каталоге, так и в контейнерах внутри хранилища.\n" +
            "Способы доступа к файлам в облачном хранилище BLOB\n" +
            "эДля программного доступа облачный аккаунт содержит REST API, который, свою очередь, через SDK предоставляет гораздо большие возможности: синхронную и асинхронную загрузку и выгрузку, удаление, создание, добавление в конец Append BLOB и пр. Кроме того, через SDK можно создать временную ссылку на файл, то есть ссылку, становящуюся нерабочей через определенный промежуток времени.\n" +
            "Рассмотрим подробнее, как работать с хранилищем BLOB с помощью веб- портала. Чтобы перейти к хранилищу BLOB, необходимо нажать ссылку Blobs на общей панели аккаунта. В результате откроется вкладка\n" +
            " \n" +
            " Общая панель сервиса BLOB Storage\n" +
            "Далее требуется добавить контейнеры. Для этого необходимо нажать ссылку + Container\n" +
            "Форма создания нового контейнера\n" +
            "Вданной форме указано имя (свойство Name) — pokercomm; уровень доступа (Public access level) — Private (no anonymous access). Этот тип доступа подразумевает доступ не по прямой ссылке, а только с помощью ключей аккаунта с использованием SDK. Другие варианты типа доступа: Blob (anonymous read access for blobs only) — разрешает анонимный доступ только к файлам (BLOB); Container (anonymous read access for containers and blobs) — разрешен анонимный доступ к контейнерам и файлам. Вкладка созданного контейнера выглядит следующим образом\n" +
            "  \n" +
            "Вкладка созданного контейнера\n" +
            "Загрузить файл в контейнер можно с помощью ссылки Upload. Свойства кон тейнера доступны по ссылке Container properties. Они включают в себя имя, адрес, статус, количество и суммарный размер BLOBобъектов, статус.\n" +
            "Вкладка свойств контейнера\n" +
            "Для контейнера доступна настройка политики доступа через вкладку Access policy. Эта настройка позволяет организовать различный уровень доступа к различным контейнерам и объектам BLOB.\n" +
            "Вкладка настройки политики доступа\n" +
            "Помимо упомянутых настроек, для BLOB доступен ряд других.\n" +
            "  \n" +
            " Различные настраиваемые сервисы Blob Storage\n" +
            "Самые важные параметры:\n" +
            "• CORS (сrossorigin resource sharing — совместное использование ресурсов между разными источниками) — свойство, обеспечивающее доступ к ресурсам BLOB из другого домена;\n" +
            "• Custom domain — конфигурирование DNSзаписей CNAME в целях указания домена пользователя, в дополнение к домену аккаунту Azure Storage;\n" +
            "• Encryption — шифрование объектов в хранилище;\n" +
            "• Azure CDN — конфигурирование Azure Content Delivery Network, которая служит для хранения часто используемого контента из хранилища BLOB с анонимным доступом.\n" +
            "Как уже было сказано, доступ к объектам в BLOB Storage возможен по прямой ссылке URL или с помощью интерфейса REST API (напрямую либо через SDK). Данный способ хранения обеспечивает самый быстрый доступ (минимальное время загрузки/выгрузки), но требует применения специальных программных клиентов, взаимодействующих с этими API. Последнее условие может помешать существующим приложениям большого масштаба мигрировать в облако.\n" +
            "Кроме того, в ряде случаев нужно создать облачное хранилище, которое должно быть доступно из виртуальной машины без всяких «самописных» программных клиентов. Для этого в хранилище BLOB можно разместить\n" +
            "\n" +
            "виртуальный жесткий диск (или набор дисков для RAIDмассива) и примонтировать его к виртуальной машине.\n" +
            "Преимущество такого решения состоит в том, что данные из виртуальной машины могут быть доступны точно таким же образом, как и c физического диска, подключенного к ней. Недостаток такого способа заключается в его низкой масштабируемости (верхний предел размера ограничен на уровне, определяемом операционной системой виртуальной машины и типом ее устройства ввода-вывода), дороговизне, а также в недоступности файлов извне по прямой ссылке.\n" +
            "Скорость доступа к файлам тоже определяется конфигурацией топологии соединения дисков в массив RAID и в ряде ситуаций существенно ниже, чем в случае BLOB. Кроме того, один VHD может быть примонтирован строго к одной виртуальной машине. Невозможный или затрудненный доступ к файлам извне, также сложности при конфигурировании совместного доступа к файлам из нескольких виртуальных машин значительно ограничивают возможности такого хранилища в облачных архитектурах для оперирования больших данных. Чтобы преодолеть эти ограничения и одновременно обеспечить работу с файлами стандартными средствами операционных систем и программных библиотек вводавывода, следует использовать облачное файловое хранилище Azure File Storage\n" +
            "Способы доступа к облачному файловому хранилищу Azure File Storage\n" +
            "Итак, сервис Azure File Storage составляет часть Azure Storage Account. Каждый Storage Account может включать в себя одну или несколько шар (share). Чтобы создать новую шару, необходимо c общей панели (см. рис. 4.7) добавить вкладку, нажав + File share. В появившейся форме (рис. 4.21) указывается имя шары (Name) — в нашем примере это pokerfileshare — и\n" +
            " \n" +
            "ее размер (Quota), в данном случае 10 Гбайт. Размер каждой шары (квота) может изменяться (с помощью вебпортала, SDKуправления облачными ресурсами или Azure CLI) и способна достигать 5 Тбайт.\n" +
            "Форма добавления новой файловой шары\n" +
            "Ключевым отличием шары от контейнера является то, что для нее устанавливается квота — верхний предел размера. Эта шара представляет собой корневой каталог, который доступен по протоколу SMB 3.0 и может быть примонтирован\n" +
            "квиртуальным машинам в том же аккаунте Azure и в том же регионе, что и Azure File Storage.\n" +
            "Наиболее важными опциями конфигурирования является возможность подключения (Connect) к виртуальной машине и создание мгновенного снимка (View snapshot).\n" +
            "  Доступные опции конфигурирования файловой шары\n" +
            "\n" +
            "Чтобы подключить шару File Storage к виртуальной машине, в оболочке виртуальной машины нужно выполнить команду монтирования сетевого диска. Эта команда может быть получена напрямую на вебпортале после щелчка на ссылке Connect\n" +
            "Вкладка Connect Azure File Storage\n" +
            "Достоинства файлового хранилища представлены ниже.\n" +
            "• Возможность прямой миграции файловой системы из локального хранилища в облачное. Будет полностью сохранена иерархия этой системы (вероятные ограничения на символьную длину пути и глубину вложенности каталогов см. в документации).\n" +
            "• Простота взаимодействия из всех программных продуктов, реализующих стандартные интерфейсы ввода-вывода. Не требуется никаких модификаций кода программ, они могут быть устаревшими и все равно будут работать с Azure File Storage, поскольку это хранилище монтируется к основной файловой системе виртуальной машины на уровне операционной системы.\n" +
            " \n" +
            "• Возможен просмотр списка файлов с помощью стандартных средств Windows или Linux.\n" +
            "Недостатки файлового хранилища:\n" +
            "• ограниченный размер файловой шары (5 Тбайт) и одного файла (1 Тбайт); более высокая по сравнению с BLOB Storage цена за гигабайт;\n" +
            "• меньшая по сравнению с BLOB Storage производительность операций чтения-записи.\n");
        add("Принципы построения, проектирования и эксплуатации ИС. Лекция 1.\n" +
            "Современное состояние Computer Science характеризуется тем, что, помимо естественных данных — результатов научных наблюдений, метеорологических данных, социологических и др., — появляется огромное количество данных, связанных\n" +
            "сработой информационных систем. Эти новые данные существенно отличаются от тех, что анализировались на заре компьютерной эры. Те старые данные (их можно условно назвать естественнонаучными) в основном требовали математической обработки.\n" +
            "В отличие от них данные современных информационных систем (большие данные) не могут быть представлены простыми математическими моделями, чьи параметры следует определить. Кроме того, эти данные отличаются существенной неоднородностью, разнообразной и непредсказуемой структурой, и зачастую непонятно, как их обрабатывать и нужно ли это вообще? Можно ли в них найти чтолибо полезное? Этих данных настолько много, что их анализ за разумное время требует вычислительных ресурсов, существенно превышающих вычислительныe ресурсы самой информационной системы. Это значит, что данные часто лежат мертвым грузом, несмотря на скрытые в них закономерности, составляющие полезную информацию, которую требуется найти. Поиск таких закономерностей называется Data Mining — добывание данных из груды пустых данных (по аналогии\n" +
            "спустой породой). Что значит «обрабатывать» данные, и как их добывать? Для ответа на все приведенные вопросы необходимо сначала выяснить, откуда берутся эти большие данные. Их источниками могут быть:\n" +
            "• социальные сети — посты, комментарии, сообщения между пользователями и пр.;\n" +
            "• события, связанные с действиями пользователей в веб или мобильных приложениях;\n" +
            "• логи приложений;\n" +
            "• телеметрия сети устройств из мира «Интернета вещей» (Internet of Things, IoT); потоки событий крупных вебприложений;\n" +
            "• потоки транзакций банковских платежей с метаданными (время, место платежа и т.д.).\n" +
            "Все эти данные должны быть обработаны в режиме реального времени или же постфактум. В обоих случаях они могут размещаться в различных хранилищах (как общего назначения, так и специализированных) и в разных форматах: CVS, XML, JSON, таблицы в реляционных БД, базах данных NoSQL и пр.\n" +
            "Для пакетной обработки исторических данных различных форматов, расположенных в разных хранилищах, необходим единый подход,\n" +
            "\n" +
            "обеспечивающий выполнение запросов к данным, хранящимся в указанных выше форматах. В настоящее время распространены следующие подходы.\n" +
            "1.Преобразование данных из различных форматов в общий, допускающий выполнение запросов к единообразным данным. Это можно сделать с помощью облачных сервисов трансформации и копирования, таких как Azure Data Factory и AWS Glue, которые консолидируют данные из разных источников в один. Такое хранилище традиционно называется Data Warehouse (DWH, «склад данных»), а преобразование данных — ETL (Extract Transform Load — «извлечение, преобразование, загрузка»). Данный подход достаточно распространен в традиционных системах, в которых DWH строится на основе кластера SQLсерверов. Подход позволяет использовать все элементы синтаксиса SQL.\n" +
            "2. Складирование данных в единое хранилище без изменения формата. При этом форматы данных остаются прежними (JSON, XML, CSV и т. д). Такое хранилище, в котором данные размещаются в виде несвязанного набора данных, называется Data Lake («озеро данных»). Файловая система, лежащая в основе подобных хранилищ, совместима с HDFS — распределенной файловой системой, которая, в свою очередь, совместима с Hadoop (Azure Data Lake, AWS EMRFS). Такое хранилище позволяет задействовать сервисы из экосистемы Hadoop (например, Hive, Apache Spark и др.) и применять иной подход к операциям\n" +
            "с данными: ELT (Extract Load Transform — «извлечение, загрузка, преобразование»), когда данные можно трансформировать после загрузки. При этом используется сервер аналитики или кластер серверов, содержащий процессор специализированного языка запросов, в котором все разнородные источники данных представляются как внешние источники данных, к которым применим SQLподобный синтаксис. Для подобного хранилища также может использоваться подход MapReduce (будет более подробно описан далее) и обработка данных в оперативной памяти (in memory processing).\n" +
            "3. Кроме того, для обработки потоковых данных существуют специализированные сервисы, допускающие обработку потока сообщений с помощью SQLподобного синтаксиса (например, сервисы Azure Stream Analytics, AWS Kinesis Analytics) или программных структур (Apache Spark Streaming), а также сервисы для приема и концентрации этих сообщений (например, Azure Event Hub, Kafka, Azure Spark и пр.).\n" +
            "Прежде всего большие данные - это огромные массивы данных или потоки,\n" +
            "которые содержат подлежащую извлечению информацию, или же умеренно большие объемы данных, требующие быстрой интерактивной обработки с целью исследования, проверки гипотез, тренировки алгоритмов машинного обучения. Для выполнения этой обработки необходим высокий уровень параллелизма,\n" +
            "\n" +
            "большой объем оперативной памяти (для in memory processing), что достигается применением кластеров виртуальных машин. Вот тутто и проявляются все преимущества облачных сред: модель IaaS позволяет создавать кластеры удалять их по требованию с минимальными затратами. Виртуальные серверы создаются и задействуются только в течение того промежутка времени, когда они нужны, и, соответственно, плата за них взимается только во время прямого использования. Но просто создание кластера для обработки больших данных с последующей установкой требуемых программ и их настройкой — весьма трудоемкое занятие. Кроме того, облачные провайдеры предоставляют отдельные сервисы PaaS больших данных.\n" +
            "Обработка больших данных\n" +
            "Большие данные могут быть обработаны в пакетном режиме, когда они уже присутствуют в хранилище. Чаще всего это необходимо для агрегирования данных и построения аналитических отчетов на их основе. Рассмотрим в качестве примера систему мониторинга электроэнергии сети зданий. В этой системе замеры потребляемой мощности передаются с малой периодичностью как сообщения от каждого измерительного модуля. Чтобы получить величину дневного потребления электроэнергии, необходимо сложить все замеры сизмерительного модуля каждого пользователя в отдельности. Если итоговый результат нужно, к примеру, формировать в виде ежедневного (еженедельного, ежемесячного и пр.) отчета, то наиболее просто реализовать такую систему следующим образом.\n" +
            "Архитектура системы учета электроэнергии, построенная на основе разделения хранилищ сырых и агрегированных данных — так называемая лямбдаархитектура\n" +
            "Все сообщения от измерительных устройств можно хранить в нереляционном хранилище табличного типа (этот вопрос подробнее рассматривается в части II), например HBase или Cassandra. Каждая строка таблицы будет содержать\n" +
            " \n" +
            "временну'ю метку (то есть время поступления или отправления сообщения), идентификатор устройства, его отправившего, и собственно величину замера.\n" +
            "Для построения периодического отчета с помощью системы бизнесаналитики (business intelligence, BI) (например, PowerBI или Microsoft SSRS) или отображения этой величины в браузере необходимо, чтобы данные в агрегированном виде были размещены в БД SQL. А почему нельзя сразу размещать их непосредственно\n" +
            "вэтой базе? Посчитаем. Предположим, что измерительное устройство отсылает сообщения каждые пять минут. Это значит — 12 отсчетов в час, или около 105 тыс.\n" +
            "вгод. Теперь предположим, что система мониторинга собирает данные энергопотребления с каждого устройства заказчика, которых могут быть десятки, а самих заказчиков — тысячи. В итоге таблица, хранящая события в реляционной БД, будет содержать многие миллионы строк: допустим, при наличии 100 заказчиков со средним числом подключенных приборов 20 за год такая таблица пополнится 200 миллионами строк. Вот они, большие данные!\n" +
            "Простое применение запроса на выборку данных к подобной таблице может занять очень много время. А если добавить еще необходимость постоянных запросов на обновление таблицы поступающими от устройств сообщениями, а также постоянные запросы от вебпортала или от пользователей на получение отчетов, то станут очевидны будущие проблемы такой архитектуры с одной базой данных. Пакетная же обработка с группировкой и суммированием результатов может быть выполнена, например, с использованием Hadoop MapReduce или Apache Spark. Сами алгоритмы группировки в данном случае можно реализовать с помощью программ на Java (для MapReduce, Spark) или Python (Spark) и запустить в кластере.\n" +
            "Витоге размеры таблицы с агрегированными данными в базе данных SQL будут существенно меньше, чем в таблице с сырыми данными. Так, если хранится часовое агрегирование, то в SQLтаблице в 12 раз меньше строк, чем в NoSQL, а если суточное — то в 288 раз. При этом для клиентов запрос на получение данных будет очень простой и высокопроизводительный: выбрать из таблицы агрегатов строки, отфильтрованные по идентификатору заказчика и по требуемому временно'му интервалу без каких бы то ни было группировок в самом запросе.\n" +
            "По поводу подобной архитектуры следует сделать целый ряд замечаний.\n" +
            "1.Обеспечить высокую точность позволяет большое количество замеров, следующих с малым временны'м интервалом. Если интервал постоянный, то можно упустить включение/выключение прибора, произошедшее между замерами. Эта проблема решается путем передачи не периодических замеров, а замеров, приуроченных к событию: включению или изменению величины проходящей мощности более чем на заданную величину. Такое решение, вопервых, разгрузит сеть от слишком частых передач отсчетов (но не\n" +
            "\n" +
            "полностью — необходимо оставить периодические сообщения от измерителя о его работоспособности), и вовторых, существенно уменьшит объем сырой таблицы.\n" +
            "2. В случае проблем с сетью и для обеспечения высокой точности вместе с требованием разгрузки сети необходимо физическое разделение отсчетов замера мощности на уровне АЦП измерительного прибора (они могут быть выполнены с высокой частотой дискретизации) и отсылка результатов суммирования измерений в виде сообщения в систему. Чтобы обеспечить это разделение, измерительное устройство должно быть достаточно «интеллектуальным»: обладать памятью и иметь возможность синхронизировать часы, чтобы установить временну'ю метку. Может показаться, что достаточно иметь момент времени приема сообщения, но это неверно. Для получения высокой точности и обеспечения надежности важно каждое сообщение. Они могут быть потеряны как изза отказа измерительного устройства, так и изза проблем с телекоммуникационной сетью. Чтобы устранить проблемы с сетью, устройство может запоминать сообщения и пересылать их, когда сеть восстановит работоспособность. И вот тутто очень важно, чтобы каждому сообщению была присвоена метка времени: когда оно сгенерировано. Это позволит в итоге правильно подсчитать суммарное энергопотребление в заданный временной интервал.\n" +
            "Теперь рассмотрим еще один вопрос: а зачем вообще нужно промежуточное хранилище такого большого объема?\n" +
            "Архитектура системы учета электроэнергии, построенная на основе единого реляционного хранилища данных\n" +
            "Ведь можно периодически очищать сырую таблицу в SQL хранилище после заполнения данными агрегированной таблицы и хранить только результаты агрегирования. Действительно, при наличии данных энергопотребления в\n" +
            " \n" +
            "течение каждого дня недели/месяца/года можно легко подсчитать суммарное энергопотребление за бо'льшие периоды времени. Против такого подхода есть ряд возражений. Например, возможна ситуация, когда изза проблем с сетью не все устройства отослали свои данные вовремя. И если сырая таблица очистится перед тем, как восстановится работоспособность сети и устройства сбросят свои данные, то последние останутся неучтенными и не будет никакого смысла дополнительно усложнять измерители в виде внутреннего буфера сообщений и синхронизиру емых часов. В то же время реализация дополнительной логики, обеспечивающей пересчет агрегированных данных в пакетном режиме при приеме недостающих сообщений, позволит произвести правильный и надежный подсчет потребления даже при ненадежной сети передачи данных.\n" +
            "Тут мы сталкиваемся еще с одним аспектом анализа больших данных: потоковой обработкой. В данном случае необходимо из всего потока сообщений обнаруживать те, чья временна'я метка меньше, чем текущее время минус самая большая временная задержка, и при их обнаружении запускать внепланово или планировать дополнительно запустить в определенное время (если построение агрегированных таблиц происходит в конкретное время, скажем по ночам) задачу по повторному пересчету. Для этой цели может служить, например, Apache Storm, Apache Spark Streaming или же Apache Pig.\n" +
            "Следующая причина, побуждающая оставитьтаки сырую таблицу без удаления данных, — возможность провести интерактивный анализ хранящихся в ней данных. То есть применить к ним запросы на специальном языке, позволяющем комбинировать, фильтровать, группировать, проводить арифметические операции в режиме реального времени. Это позволяет находить скрытые закономерности в данных, например определять пики энергопотребления, устанавливать корреляцию их с внешними событиями (скажем, с погодой), определять профили пользователей, характеризующиеся оптимальным энергопотреблением. Или для одного пользователя строить типовой профиль применения энергоресурсов и обнаруживать отклонения от него (допустим, утечку электроэнергии, несвоевременное выключение освещения и пр.). Подобные задачи могут решаться с помощью системы интерактивного анализа данных, таких как Spark SQL или Apache Hive, арасширенный интеллектуальный анализ — благодаря применению библиотеки машинного обучения Spark MLib.\n" +
            "Архитектура, содержащая в своем составе хранилища как сырых данных, так и агрегированных, является очень гибкой и позволит создать не просто очередную систему учета электроэнергии, но и интеллектуальную, которая может «подсказать», как уменьшить потребление энергии, где есть узкие места, а это уже принципиально новый уровень по сравнению с простой телеметрией. Такое развитие возможно благодаря тому, что данные в ней хранятся в том виде, в котором они наиболее удобны для выполнения анализа различными сервисами:\n" +
            "\n" +
            "для обычного сервиса построения отчетов об энергопотреблении — в агрегированном виде, а для целей Data Mining — в сыром.\n" +
            "Ключевой момент всех технологий, работающих с большими данными, — возможность распараллеливания выполняемых задач, областей хранения, памяти и т. д. между группой компьютеров (кластер). Кроме того, эти технологии должны:\n" +
            "• обладать возможностью линейного масштабирования и наращивания производительности путем добавления новых серверов в кластер. Линейность масштабирования означает пропорциональность производительности/объема хранения количеству компьютеров в кластере;\n" +
            "• иметь специальную файловую систему для надежного хранения и доступа\n" +
            "• данным, позволяющую оперировать очень большими объемами данных и допускать их репликацию в целях повышения надежности и производительности;\n" +
            "• позволять выполнять запросы к файлам с помощью специального языка запросов или программного интерфейса;\n" +
            "• иметь планировщик, позволяющий распределять эти запросы среди узлов кластера для обеспечения их параллельной работы.\n"
    );
        add("Принципы построения, проектирования и эксплуатации ИС. Лекция 2.\n" +
            "Облачные провайдеры позволяют подключать различные устройства, программные продукты, сервисы (игровые устройства, стационарные устройства IoT, подключенные автомобили, мобильные приложения, вебсерверы и серверы приложений, медиасервисы и пр.) через специальные сервисы концентраторов сообщений и шлюзы устройств «Интернета вещей» (IoT Gateway). Концентраторы (AWS Kinesis Stream, Azure Event Hub) обеспечивают однонаправленный прием сообщений извне в облако, а IoTшлюз (Azure IoT Hub) — двунаправленную коммуникацию с устройствами, то есть возможность обратной отсылки команд устройствам из облака. Этот поток может быть обработан сервисами потоковой обработки и анализа.\n" +
            "К сервисам потокового анализа относятся сервисы, которые допускают интерактивный анализ потока данных и позволяют создавать аналитические запросы на специальном языке (чаще всего с SQLподобным синтаксисом), интерактивно их применять и отображать результаты (например, Azure Stream Analytics). К сервисам потоковой обработки относятся те, которые задействуют модули, написанные на компилируемых языках для построения потоковых задач анализа (таких как Apache Storm в HDInsight или AWS EMR) и не допускающие интерактивного использования.\n" +
            "Облачные сервисы, относящиеся к большим данным\n" +
            " \n" +
            "Сообщения, полученные от концентраторов или IoTшлюзов, могут быть направлены по своим назначениям, в зависимости от внутренних признаков (такая возможность обеспечивается системой маршрутизации сообщений: Azure Event Grid или аналогичной системой в IoTшлюзе), или целиком направлены в облачное хранилище. Это может быть либо хранилище общего назначения (типа Azure BLOB Storage или AWS S3), либо HDFSсовместимое (Azure Data Lake). Кроме того, данные в такое хранилище могут доставляться сервисами копирования и трансформации данных (AWS Glue или Azure DataFactoy) или специа лизированными сторонними программами через предоставляемые этими сервисами API. Источниками данных могут быть внешние реляционные и нереляционные базы данных и файлы. После размещения в облачном хранилище информацию можно обработать в пакетном режиме (например, с помощью Hadoop MapRerduce в Azure HDInsight или AWS EMR), интерактивном режиме (Azure Data Lake Analytics, AWS Athena) или с применением машинного обучения. Результаты обработки могут быть размещены в реляционном хранилище данных и доступны для средств BI (Microsoft PowerBI или AWS QuickSight).\n" +
            "Любой облачный провайдер предоставляет сервисы IaaS, позволяющие создать ряд виртуальных машин, которые можно объединить в кластер. В этом случае пользователю придется самому создавать и конфигурировать нужный BigDataфреймворк. Ситуация в какойто мере облегчается тем, что имеются готовые образы виртуальных машин с предустановленными утилитами и компонентами. Но реализация IaaSрешения требует достаточно высокой квалификации у пользователей облачных сред. Ведь, помимо навыков инсталляции и конфигурирования образцов виртуальных машин, необходимо оперировать сервисами IaaS, чтобы построить нужную инфраструктуру, что требует больших затрат времени и обширных знаний, не относящихся к области BigData. Частично задачу упрощает тот факт, что облачные сервисы можно создавать с помощью шаблонов: AWS CloudFormation или Azure ARM Template. Но остаются сложности интеграции IaaSрешения с другими сервисами, сервисами логирования и мониторинга.\n" +
            "В то же время для каждого описанного компонента общей архитектуры, у облачных провайдеров Microsoft Azure и AWS существует свой PaaSсервис. Но у обоих провайдеров для ряда компонентов имеются два вида сервисов.\n" +
            "К первому виду относятся сервисы, которые целиком применяют существующие фреймворки больших данных из экосистемы Hadoop. Задействуются стандартные средства взаимодействия с пользователем (например, Jupiter Notebook для написания запросов и отображения результатов). При этом создание, конфигурирование и масштабирование кластера полностью автоматизировано. К таким сервисам относятся Azure\n" +
            "\n" +
            " HDInsight и AWS EMR. Они позволяют разворачивать кластеры Hadoop, Spark, Storm, HBase, Kafka и RServer (только Azure). Кроме того, компоненты облачных сервисов могут быть размещены на кластерах AWS ECS / EKS или Azure Kontainer Services в Docker контейнерах. Ко второму виду относятся облачные сервисы, целиком и полностью (нативно) предоставляемые облачными провайдерами. Такие сервисы конфигурируются и управляются только из облачного портала или через его REST API и не используют сторонние средства и сервисы.\n" +
            "Архитектуры традиционных информационных систем\n" +
            "Для получения представления о том, что такое большие данные, как они возникают и обрабатываются, следует подробнее разобраться с тем, что собой представляют современные информационные системы. Системы обработки больших данных подразумевают возможность, позволяющую реализовать не только систему обработки данных, но и приложение, которое решает конкретную бизнес-задачу. Эта идея — асинхронная передача сообщений (событий) между компонентами системы и применение отдельных сервисов, обеспечивающих надежную передачу сообщений. Казалось бы, практически любая информационная система имеет дело с обменом сообщений, представленном в том или ином виде, так что тут нового? Разберемся по порядку.\n" +
            "Многие годы информационные системы строились в виде одного крупного монолита с единообразной кодовой базой, которая разворачивается на сервере как единое целое: вместе со всеми подключаемыми модулями, библиотеками и т. д. Такой монолит (рис. 3.2) отвечал за все (или почти): за взаимодействие с базами данных, обеспечение системы контроля учетных данных, работу периодических сервисов синхронизации, логирования и пр.\n" +
            "Ниже представлены проблемы, свойственные такой архитектуре.\n" +
            "• Любое изменение в любом компоненте монолита, даже самое незначительное, требует компилирования и разворачивания всей системы, что при большом размере монолита задача весьма небыстрая.\n" +
            "• Монолит очень плохо масштабируется и подвержен существенным проблемам использованием ресурсов. Действительно, как правило, подобные архитектуры разворачиваются на одном сервере или в виде полных копий на группе серверов. Поэтому любой компонент (или компоненты), который задействует ресурсы сервера (скажем, оперативную память, процессор и т. д.), в значительной степени может затруднить работу всего монолита и потребует увеличения производительности всего сервера, на котором расположена данная\n" +
            "\n" +
            "архитектура. Компоненты монолита невозможно масштабировать\n" +
            "независимо.\n" +
            "• Монолит жестко диктует стек технологий программирования, и\n" +
            "обновить его, также обновить саму архитектуру — значит, по сути, переписать весь код заново. Сюда же можно отнести проблемы с быстрым «старением» монолита, склонностью к обрастанию спагеттикодом, а также «тупиковой внутренней архитектурой» — это когда невозможно исправить баг или улучшить чтолибо, не вызвав появления нового бага или ухудшения системы.\n" +
            "• Сопровождение монолита может причинить множество неудобств программистам, системным администраторам, тестировщикам...\n" +
            "Монолитная архитектура\n" +
            "Решить указанные проблемы была призвана многослойная архитектура\n" +
            "  \n" +
            "Многослойная архитектура\n" +
            "В ней за специфическую задачу отвечает отдельный слой: пользовательского интерфейса (user interface layer, UI layer), бизнеслогики (business logic layer, BL layer) и доступа к данным (data access layer, DAL).\n" +
            "Рассмотрим эту архитектуру подробнее. Каждый слой отвечает только за определенную группу задач. UIслой содержит только вебсерверы, являющиеся источником вебстраниц, или размещает сервисы (REST, SOAP или др.) для взаимодействия с клиентскими приложениями. Кроме того, данный слой принимает запросы от клиентов и транслирует их слою бизнеслогики. Поскольку с клиентом напрямую взаимодействует только UIслой, то на одном уровне с ним в тесной интеграции находится сервис аутентификации клиентов. Слой BL содержит серверы приложений и отвечает, собственно, за бизнеслогику и интеграцию со сторонними сервисами. Слой DAL обеспечивает программный доступ слоя BL к базе данных и файловому хранилищу.\n" +
            "Подобная архитектура по сравнению с монолитной имеет следующие преимущества.\n" +
            "• Разделение на слои позволяет реализовать в каждом слое наиболее подходящий для него стек технологий. Можно независимо обновлять фреймворки на каждом слое.\n" +
            "• Логическое разделение на слои существенно упрощает процесс разработки и сопровождение всей системы. Распределение команд программистов по слоям и специализация разработчиков (фронтенд, бэкенд), уменьшение объема кода на каждом слое, а также независимый деплой (развертывание) значительно улучшают качество всей системы, делая ее более гибкой и пригодной для сопровождения.\n" +
            "• Возможно независимое масштабирование каждого слоя.\n" +
            "Наиболее часто подобная архитектура реализуется в виде серверов, расположенных в локальной сети, разбитой на подсети с настроенными фаерволами. Адреса серверов (IP или URL) разных слоев и учетные данные для доступа к ним прописаны в конфигурационных файлах других серверов. В этой архитектуре уже необходимо централизованно хранить учетные данные, иметь серверы DNS, сервис хранения логов и мониторинга, а также сервер для администрирования.\n" +
            "Вмонолитной архитектуре все это могло быть расположено на одном большом общем сервере. Логирование также было весьма простым, поскольку вся система строилась в рамках одного стека технологий. В многослойной архитектуре каждый слой может генерировать логи,\n" +
            "\n" +
            "существенно отличающиеся от логов другого слоя. Кроме того, увеличение количества серверов тоже ведет к увеличению количества и видов логов.\n" +
            "Многослойная архитектура информационных систем в настоящее время чрезвычайно распространена, она более гибкая и удобная по сравнению с монолитной, однако не может решить ряд проблем. В частности, при разрастании проекта до такого масштаба, что слой BL становится сопоставимым с монолитом, появляются аналогичные проблемы с масштабированием, производительностью, сопровождением и т. д.\n" +
            "Следующая разновидность многослойной архитектуры — SOA: сервис- ориентированная архитектура. Ее квинтэссенцией является архитектура микросервисов, суть которой заключается в том, что каждое приложение разбивается на наименьшие самостоятельные модули, и каждый из них отвечает только за один аспект: отсылку писем, загрузку и выгрузку файлов и пр. Каждый такой сервис можно совершенно независимо развернуть и обновить в любой момент, не затрагивая остальные сервисы. Код подобного сервиса может быть совсем небольшим, и для его сопровождения нужна маленькая команда. Более того, все микросервисы можно писать на разных языках, лучше всего подходящих для решения текущей задачи. И наконец, каждый микросервис может быть развернут на своем сервере или в кластере серверов, которые могут быть совершенно независимо масштабируемы. Каждый сервис доступен по URL конечной точки и из них, как из элементов конструктора, можно собрать новые системы, а каждый сервис использовать в различных системах.\n" +
            "Архитектура микросервисов\n" +
            " \n" +
            "Однако работа с микросервисной архитектурой предполагает ряд трудностей.\n" +
            "• Большое количество сервисов, размещенных на многих серверах, означает большое количество разнообразных логов. По сути, вот они, большие данные! Анализ этих данных, определение метрик производительности, узких мест, поиск логов и отображение результатов в виде графиков в режиме, близкому режиму реального времени, требует не просто сервиса, но целой подсистемы, сопоставимой с основной системой. В качестве примера такой подсистемы можно привести ELK стек — Elasticsearch (хранение логов и поиск), Logstash (агенты, обеспечивающие доставку логов с серверов в кластер Elasticsearch) и Kibana (интерактивные диаграммы, графики и др.), Splunk.\n" +
            "• Взаимодействие между сервисами происходит преимущественно с помощью REST. А потому каждый сервис должен знать URL всех сервисов, с которыми он может потенциально взаимодействовать.\n" +
            "• Если по какойто причине запрос не был обработан (например, сервис был недоступен), то для его повторения необходимо организовать логику повтора в рамках самого кода.\n" +
            "Синхронизировать работу микросервисов позволит отдельный сервис, обеспечивающий надежную доставку сообщений, а также предоставляющий малое количество конечных точек. И вот тут мы постепенно подходим к Event Driven Design — архитектуре, основанной на обмене сообщениями.\n" +
            "Архитектуры, построенные на базе микросервисов, каждый из которых можно разместить в кластере серверов, дополненные сервисами обмена сообщениями (брокерами сообщений — message brokers), могут быть чрезвычайно масштабируемыми. Для этого нужно, чтобы сами сервисы обмена сообщениями были масштабируемыми. Брокеры, как правило, имеют архитектуру с одним или несколькими головными узлами, отвечающими за управление кластером, и исполнительными узлами, на которых выполняются необходимые вычисления и хранятся данные (сообщения). Чтобы обеспечить надежность кластера, данные могут быть реплицированы между исполнительными узлами.\n" +
            " \n" +
            "Общая структура масштабируемой системы, построенной на основе кластера\n" +
            "Подобные структуры весьма сложны: кластеры серверов, балансировщики нагрузки, системы управления конфигурацией, логирования и пр.\n" +
            "Исейчас самое время напомнить преимущества облачных платформ: все подобные системы представляются как сервисы — AWS ECS и Azure Service Fabric. Данные сервисы отвечают за масштабирование, мониторинг, развертывание приложений или контейнеров на них.\n" +
            "В облачных средах, наряду с сервисами PaaS, отвечающими за обработку больших данных, Azure и AWS предоставляют сервисы, занимающие промежуточное положение между IaaS и PaaS. Эти сервисы позволяют применять наиболее популярные фреймворки, работающие с большими данными, — Apache Spark, Storm, Kafka, HBase, Storm и ряд других. К таким сервисам относятся AWS EMR и Azure HDInsight. Они берут на себя все трудности, связанные с настройкой и конфигурированием сервисов в кластерах, а конечному пользователю предоставляют готовый и настроенный сервис. Это очень большое преимущество подобных сервисов по сравнению с ручным конфигурированием кластера из виртуальных машин. Практически все сервисы Apache Hadoop являются продуктами с открытым исходным кодом, имеют подробную документацию и поддержку обширного сообщества, однако их установка, настройка и конфигурирование на практике очень трудны.\n" +
            "Сервисы AWS EMR и Azure HDInsight занимают промежуточное положение между IaaS и PaaS, сочетая все возможности сервисов Apache с простотой PaaS. Эти сервисы представляют собой надстройки над набором виртуальных машин. Последние создаются, запускаются, останавливаются и удаляются только на время выполнения задания в сервисе или по мере надобности (как в случае Apache Kafka, например). Сервисы AWS EMR и Azure HDInsight очень хорошо интегрируются сервисами копирования и трансформации данных (Azure Data Factory), составляя, по сути, вычислительные ресурсы для заданий ETL. При создании кластеров с портала для HDInsight и AWS EMR указываются размеры виртуальных машин и сценарий, который должен выполняться при запуске сервиса. Создание и удаление управляемых кластеров полностью автоматизируемо, что и обусловливает удобство их использования в случае построения систем пакетного анализа, копирования и трансформации данных.\n" +
            "Бессерверные архитектуры\n" +
            "Архитектура, основанная на обмене сообщениями, характеризуется тем, что все компоненты системы взаимодействуют через малые порции сообщений, требующие вычислительных ресурсов только непосредственно в момент обработки сообщений. Все остальное время сервисы заняты только\n" +
            "\n" +
            "тем, что прослушивают конечные точки сервисов обмена сообщениями. Во время прослушивания серверы или виртуальные машины не загружены. Но в облачных средах принимается плата за включенную виртуальную машину вне зависимости от того, насколько интенсивно она используется. Таким образом, если поток сообщений не слишком сильный, то сервисы работают вхолостую. Но зачастую необходимо выполнить программу однократно или в непредсказуемые моменты времени в ответ на поступившее сообщение, для чего использовать виртуальную машину нецелесообразно. Для такого случая облачные провайдеры обеспечивают возможность выполнения кода по требованию без предоставления серверов — бессерверные сервисы (serverless). Подобный сервис от Microsoft называется Microsoft Azure Function, а от AWS — AWS Lambda. Последний является классическим вариантом. Этот сервис позволяет размещать исполняемый код и запускать его внешним событием, которое может прийти от сервисов SNS, SQS, Kinesis Stream, S3, API Gateway и др. Сам сервис имеет различные уровни производительности процессора и памяти, которые используются лишь при исполнении кода, и плата начисляется только этот момент.\n" +
            "Концепция serverless очень удобна для построения приложений с малым, средним и умеренно большим потоком сообщений.\n" +
            "Главные преимущества serverless таковы:\n" +
            "• более дешевая среда исполнения кода, чем виртуальные машины, при небольших, средних и умеренно больших потоках;\n" +
            "• более высокая надежность сервиса, чем в случае одиночной виртуальной машины, — SLA на уровне 99,9 %;\n" +
            "• простота интеграции с другими облачными сервисами, не требующая внесения изменения в код;\n" +
            "• простота развертывания кода и конфигурирования — необходимо только добавить код напрямую или через ZIP файл и выбрать уровень производительности.\n" +
            "Однако подобным сервисам присущи и недостатки:\n" +
            "• ограниченная масштабируемость;\n" +
            "• ограниченное время выполнения кода;\n" +
            "Но вместе с тем serverless сервисы крайне удобны для построения архитектур, основанных на событиях (event driven design).\n");
        add("Принципы построения, проектирования и эксплуатации ИС. Лекция 3.\n" +
            "Облачные хранилища файлов — это сервисы, которые обеспечивают хранение файлов, предоставляют доступ к ним с помощью REST API, позволяют скачивание по прямой ссылке (постоянной или с конечным сроком действия) и в некоторых случаях предоставляют доступ к файловой системе по протоколу SMB.\n" +
            "Хранить файлы, содержащие большие данные, в облачном хранилище очень дешево и в ряде случаев удобнее, чем в других хранилищах. Наиболее типовой пример размещения данных — это хранение файлов логов приложения, которые копируются туда периодически из сервера источника или создаются и заполняются специальной программой клиентом, размещенной на сервере источнике логов.\n" +
            "Кроме того, в облачных файловых хранилищах могут размещаться виртуальные жесткие диски (virtual hard drive, VHD) облачных виртуальных машин, на которых,\n" +
            "всвою очередь, тоже можно размещать файлы. Но в этом случае ответственность за доступность информации ложится на владельца виртуальных машин. Рассмотрим подробнее различные форматы хранения больших данных.\n" +
            " Структура потока логов серверов в облачное хранилище\n" +
            "\n" +
            "Форматы хранения данных\n" +
            "Как уже отмечалось, наиболее типовой случай использования текстовых файлов для хранения больших данных — хранение логов приложений в том или ином текстовом формате. Такие файлы могут иметь расширения .log, .txt, .csv и др. Общее у этих форматов то, что логи в них, по сути, хранятся в виде таблицы (отсюда и название — табличный формат), каждая строка которой — запись конкретного события. Строка состоит из набора столбцов, разделенных некими символами. Это могут быть пробелы, символы табуляции, двоеточие, точка с запятой и т. д. Подобные файлы можно открыть с помощью любого текстового редактора (если они не очень велики), и для их анализа (например, поиска запросов с 500 ошибками) подойдут стандартные утилиты командной оболочки (grep, awk и пр.) или же специализированные сервисы аналитики (к этому вопросу мы еще вернемся). Кроме того, табличная структура подобного файла очень удобна для импорта в реляционную или нереляционную СУБД табличного типа. Особенность таких файлов — линейная структура со строго одинаковым количеством столбцов в каждой записи и в общем случае линейное время доступа к записям. Строго говоря, возможны ситуации, когда разные строки могут содержать различное количество столбцов. Например, запись в лог-файле, отражающая ошибку приложения и трассировку стека, может включать гораздо меньше строк, чем запись, отражающая какое-либо событие, характеризующее нормальную работу приложения. В общем же случае записи логов содержат как минимум временную метку. Остальные поля (уникальный идентификатор, URL, сообщение ошибки и пр.) могут и отсутствовать. Возникает вопрос: полезна ли запись с одним полем (временной меткой)? Да. Скажем, необходимо проанализировать посещаемость сайта во времени. Просуммировать запросы для заданного временного интервала (например, 15 минут) поможет именно временная метка.\n" +
            "Табличные файлы имеют и ряд неудобств в использовании. Во-первых, для доступа к элементу информации необходимо знать номер строки и номер столбца. Нет универсального стандарта или языка запросов (за исключением SQL-подобного языка специализированных сервисов аналитики, но об этом позже), что весьма затрудняет анализ логов. Во-вторых, в таких форматах очень просто добавить новую запись в конец файла, но крайне трудно и затратно вставить, удалить или изменить произвольную строку. Как правило, все программные библиотеки вводавывода позволяют добавлять строку в конец файла с помощью стандартных средств, но для произвольной манипуляции данными программисту нужно будет создать отдельную логику в коде, и эта логика весьма непроста.\n" +
            "\n" +
            "Помимо текстового файла с табличной структурой, широко распространено хранение информации в более структурированных форматах JSON, XML. Их преимущества в том, что они очень удобны для сериализации/десериализации информации в объектноориентированном виде в коде программы. Кроме того, для обоих форматов существуют стандарты выполнения запросов на выборку данных (для XML — XPath, XQuery, для JSON — JSONPath, JSONQuery). Кратко рассмотрим эти форматы.\n" +
            "JSON представляет собой формат, при котором данные хранятся в текстовом виде как объект JavaScript (аббревиатура образована от JavaScript Object Notation). В основе любого документа JSON лежит объект, который состоит из набора «ключ — значение». В качестве ключа выступают текстовые величины. В качестве значений допускаются следующие типы.\n" +
            "• Атомарный тип (для ключей PlayerId, StepId) — величина, состоящая из одного конкретного значения: строки, числа, временно'й метки.\n" +
            "• Массив (например Players) — группы величин одного типа. (Это не совсем точное определение, в общем случае все элементы массива могут быть совершенно разного типа, но, как правило, коллекции объектов, сериализуемые в JSON в реальных программах, будут иметь одинаковый тип.) В качестве типов элементов массива могут выступать атомарные типы, другие массивы или другие объекты. Массивы обозначаются прямоугольными скобками — [ ], а элементы в массиве разделяются запятыми, допустим: [ \"a\", \"c\", \"d\" ]. Доступ к элементу происходит по числовому индексу, например [0].\n" +
            "• Объект — коллекция «ключ — значение». Обозначается фигурными скобками { } и имеет синтаксис {\"key\": value}, где value может иметь атомарный тип, тип массива и объекта. По сути, эта коллекция является ассоциативным массивом, в котором для доступа к значению необходимо использовать строковый ключ.\n" +
            "Стоит заметить, что документ JSON может содержать в качестве корневого элемента не объект, а массив, например: [ { \"key\": 1 }, { \"key\": 2 }, { \"key\": 3 } ]. Это допустимо. Но в примерах, приводимых в книге, вы будете встречаться с JSONдокументами с корневыми элементами типа «объект».\n" +
            "Преимущество этого формата текстового файла — возможность описания структур произвольной глубины вложенности (объект внутри объекта, коллекция внутри объекта и пр.), что невозможно в случае табличного представления. Кроме того, существенно упрощается сериализация и десериализация объектов, особенно из JavaScriptприложения. Обработка\n" +
            "\n" +
            "JSONфайлов в специализированных СУБД (DocumentDB) описана в книге ниже, а некоторые реляционные базы данных (например, PostgresSQL) широко поддерживают этот формат. Очень важным преимуществом формата JSON является то, что он позволяет строить информационные системы с помощью одной и той же технологии на всех уровнях: начиная с документоориентированной БД, хранящей данные в формате JSON (Azure DocumentDB, MongoDB), бэкенда на основе диалекта JavaScript (например, Node.js) и заканчивая фронтендом на основе того или иного фреймворка JavaScript (например, ReactJS, Angular). Это уникальная возможность, реализованная сейчас только в рамках JavaScript/JSON (например, популярен фреймворк MEAN).\n" +
            "Кнедостаткам JSON можно отнести его «многосимвольность»: для группировки данных используются символы (запятые, скобки, кавычки), которые сами по себе не несут информации. Кроме того, присутствуют имена полей. Перечисленные недостатки проявляются наиболее ярко в случае файлов крупного размера, относящихся к большим данным. Но это неизбежная плата за возможность сериализации/десериализации сложных структур. Избавиться от части избыточных элементов синтаксиса поможет формат YAML, но пока что он используется преимущественно в качестве шаблона конфигурационных файлов (в системах Ansible, CloudFormation и др.), а не для хранения данных. Кроме того, сериализация и десериализация YAML не так широко поддерживается программными библиотеками вводавывода. Выборка значений из документа JSON происходит с первоначальной десериализацией его в объект в программном коде, что наиболее удобно и естественно происходит в языке на основе JavaScript.\n" +
            "Следующий популярный формат хранения данных в текстовых файлах — XML (eXtensible Markup Language — расширяемый язык разметки). Традиционно он использовался для разметки (markup), то есть структурирования текстовых документов. Термин «язык» (language) говорит о том, что XML содержит строгий набор синтаксических правил, на основании которых можно построить конкретное расширение (extension) этого языка. Рассмотрим, что это значит.\n" +
            "В общем случае у XML есть два основных компонента: теги и атрибуты. Тег — синтаксический элемент, ограничивающий конкретную порцию информации: <ИмяТега>Информация в текстовом виде <ИмяТега/>. Любой тег начинается открывающим (<) и закрывающим (>) символами. Информация, представленная в текстовом виде, расположена между тегами, последний из которых состоит из двух символов (/>). Возможны и вложенные структуры тегов и коллекции последних. Атрибуты относятся к конкретному тегу и представляют собой коллекцию «ключ — значение».\n" +
            "Согласно стандарту XML для тега с конкретным именем существует строго определенный набор атрибутов, причем каждый тег должен содержать\n" +
            "\n" +
            "конкретный набор атрибутов или не включать их вовсе. Возможно также построение.\n" +
            "Итак, язык XML состоит из общих правил построения синтаксиса, а расширение данного языка представляет собой конкретный набор вложенных тегов\n" +
            "и соответствующих им атрибутов, который обеспечивает упорядоченное представление конкретной структурированной информации. Существует стандартизированный способ преобразования информации из одного XML в другой с помощью XSLT — eXtensible Stylesheet Language Transformation. Это тоже XML, элементами которого является не информация, а правила, по которым она из одного типа XML преобразуется в другой. Кроме того, есть XSD (XML Schema Definition) — синтаксис, описывающий схему, то есть структуру документа. Безусловно, стандарт XML содержит еще ряд других элементов, я описал наиболее употребительные для случаев хранения данных.\n" +
            "Вотличие от JSON XML гораздо более строг и не допускает произвольной вложенности и комбинирования элементов. Например, для одного тега не допускаются разные наборы элементов. Не допускается хранение XML в виде значения атрибута (конечно, так можно сделать, ведь атрибут является текстовым значением, но это очень плохой стиль), в случае коллекции всем ее элементам необходимо иметь совершенно одинаковую схему, то есть набор тегов и атрибутов должен быть одинаков для каждого элемента. В отличие от JSON практически все основные БД поддерживают работу с XML как с самостоятельным типом данных, поскольку он достаточно строг и однозначен. Поддержка в этом случае состоит в предоставлении встроенных средств сериализации таблиц в XML и обратно. Кроме того, XML широко применяется для создания языков описания разметки гипертекстовых документов, при построении пользовательского интерфейса (HTML, XAML, RDLC и пр.).\n" +
            "Ниже представлены достоинства XML как средства хранения информации:\n" +
            "• строгость синтаксиса существенно упрощает построение систем сериализации/десериализации;\n" +
            "• этот формат широко поддерживается различными БД как встроенный тип данных;\n" +
            "• можно выполнить простое прямое преобразование в другие языки, в том числе в языки разметки графических элементов (например, HTML);\n" +
            "• существуют специальные расширения языка, описывающие различного\n" +
            "рода преобразования и трансформации (XSLT);\n" +
            "\n" +
            "• имеется стандартный способ построения запроса к элементу или выборки элементов (XPath, XQuery).\n" +
            "К недостатком данного формата можно отнести то, что он гораздо более «многословен», чем JSON, поскольку содержит больше чисто синтаксических символов.\n" +
            "Облачное хранилище Microsoft Azure Storage\n" +
            "Рассмотрим, как реализовано облачное хранилище, на примере Microsoft Azure Storage. Оно состоит из четырех сервисов: BLOB Storage, Queue Storage, Table Storage и File Storage\n" +
            "Виды сервисов Azure Storage Account\n" +
            "Непосредственно хранение информации осуществляется в сервисах BLOB, Table и File Storage. Queue Storage — это облачный сервис обмена сообщениями и синхронизации распределенных приложений. Сервис Table Storage — база данных NoSQL типа «ключ — значение», которая будет подробно описана далее в книге. Пока же сосредоточимся на Azure File и BLOB Storage.\n" +
            "Рассмотрим подробнее, как создавать Azure Storage Account и управлять с вебпортала. Прежде всего необходимо нажать ссылку добавления новых ресурсов Azure, расположенную в левом верхнем углу, — + New. Затем в открывшемся окне выбрать последовательно Storage — Storage account.\n" +
            "  \n" +
            "Добавление нового Storage account через веб-портал После нажатия ссылки Storage account откроется форма настройки\n" +
            "Storage Account.\n" +
            "Форма настройки Storage Account\n" +
            "В ней доступны следующие конфигурации.\n" +
            "• Имя аккаунта (поле Name) будет частью URL аккаунта\n" +
            "<Name>.core.windows.net,\n" +
            "• потому правила наименования ресурсов точно такие же, как и в случае\n" +
            "именования ресурсов, доступных по URL.\n" +
            "• Тип модели развертывания ресурсов (deployment model) — выбираем Resource Manager, чтобы иметь возможность добавить аккаунт к общей ресурсной группе PockerRumExample.\n" +
            "• Тип Storage (Account kind) — Storage (general purpose v1). Помимо этого, доступны типы Storage (general purpose v2) и BLOB.\n" +
            "• Выбираем уровень производительности (Performance) — Standard. В зависимости от выбранного уровня производительность операций чтениязаписи будет отличаться. Наиболее высоким уровнем будет обладать комбинация Account kind = BLOB, Performance = Premium.\n" +
            " \n" +
            "Для premiumуровня в качестве физических устройств хранения выступают SSDдиски.\n" +
            "• В качестве режима репликации (Replication) выбираем LocallyRedundant storage (LRS). Эта опция означает, что информация, хранящаяся в Storage Account, физически реплицируется три раза, но в пределах одного датацентра. Помимо LRS, доступны различные режимы географической репликации в разных датацентрах в пределах одной зоны (ZRS) или среди нескольких различных зон (GRS и ReadOnlyGRS — репликация по различным географическим зонам с репликой, доступной только для чтения). Все эти режимы различаются по стоимости и уровню надежности и доступности, что позволяет реализовать облачные хранилища, отвечающие различным наборам требований.\n" +
            "После создания Storage Account доступна следующая панель мониторинга и управления\n" +
            "Общая панель мониторинга и управления Storage Account\n" +
            "На этой панели доступны все четыре сервиса, входящие в состав Storage Account: Blob, File, Table и Queue. Далее в главе рассмотрим Blob Storage и File Storage. Сервис Table Storage представляет собой нереляционную базу данных, а Queue предназначен для синхронизации сервисов «потребитель — производитель».\n" +
            " ");
    }};
}
